{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {
    "id": "introduction"
   },
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3802b3e",
   "metadata": {
    "id": "c3802b3e"
   },
   "source": [
    "__Notebook Author__: Hamed Qazanfari\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hamedmit/Classic-ML-Algorithms/blob/main/Unsupervised_Learning/Dimensionality_Reduction/Introduction_and_Applications.ipynb)\n",
    "[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/hamedmit/Classic-ML-Algorithms/blob/main/Unsupervised_Learning/Dimensionality_Reduction/Introduction_and_Applications.ipynb)\n",
    "\n",
    "---\n",
    "## 1. Introduction to Dimensionality Reduction\n",
    "\n",
    "### What is Dimensionality Reduction?\n",
    "\n",
    "In machine learning and data analysis, we often deal with datasets that have many features (dimensions). While more features can provide more information, high-dimensional data introduces several challenges:\n",
    "\n",
    "- **Curse of Dimensionality**: As dimensions increase, the feature space grows exponentially, making data sparse. This sparsity weakens machine learning models, making it harder to find patterns.\n",
    "- **Computational Complexity**: More dimensions mean higher computational costs and longer processing times.\n",
    "- **Overfitting**: Models trained on high-dimensional data may capture noise instead of meaningful patterns.\n",
    "- **Difficulty in Visualization**: Beyond three dimensions, data visualization becomes difficult, limiting our ability to explore patterns intuitively.\n",
    "\n",
    "**Dimensionality Reduction** simplifies data by reducing the number of features while retaining essential information. This improves model performance and makes data easier to handle.\n",
    "\n",
    "Dimensionality reduction techniques fall into two main categories:\n",
    "\n",
    "- **Feature Selection**: Choosing the most important features while discarding irrelevant ones.\n",
    "- **Feature Extraction**: Transforming data into a lower-dimensional space (e.g., PCA) by creating new features that capture the most variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applications",
   "metadata": {
    "id": "applications"
   },
   "source": [
    "## 2. Applications of Dimensionality Reduction\n",
    "\n",
    "Dimensionality reduction has several important applications, including:\n",
    "\n",
    "- **Data Visualization**: Reducing data to two or three dimensions allows for better pattern recognition, clustering, and anomaly detection.\n",
    "- **Noise Reduction**: Removing irrelevant features helps in reducing noise and improving model accuracy.\n",
    "- **Feature Extraction**: Identifies and combines features that best represent the dataâ€™s variance.\n",
    "- **Faster Computation**: Fewer dimensions mean reduced processing time, improving model efficiency.\n",
    "- **Overfitting Prevention**: Lower-dimensional data reduces model complexity, improving generalization to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-visualization",
   "metadata": {
    "id": "data-visualization"
   },
   "source": [
    "### 2.1 Data Visualization\n",
    "\n",
    "**Dataset**: MNIST Handwritten Digits Dataset\n",
    "\n",
    "**Description**:\n",
    "\n",
    "The MNIST dataset consists of 70,000 images of handwritten digits (0-9), each of size 28x28 pixels, resulting in a 784-dimensional feature space. Visualizing this high-dimensional data is challenging.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "- Use PCA to reduce the dimensionality of the MNIST dataset from 784 to 2 dimensions.\n",
    "- Visualize the data in 2D to observe patterns and clusters.\n",
    "\n",
    "**Visualization**:\n",
    "\n",
    "![MNIST PCA Visualization](pics/mnist_pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noise-reduction",
   "metadata": {
    "id": "noise-reduction"
   },
   "source": [
    "### 2.2 Noise Reduction\n",
    "\n",
    "**Dataset**: Fashion MNIST Dataset with Added Noise\n",
    "\n",
    "**Description**:\n",
    "\n",
    "The Fashion MNIST dataset is similar to MNIST but contains images of clothing items. We'll add noise to the images and use PCA to reconstruct them, effectively reducing noise.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "- Add Gaussian noise to the images.\n",
    "- Use PCA to reconstruct the images from a reduced number of components.\n",
    "- Compare original, noisy, and reconstructed images to observe noise reduction.\n",
    "\n",
    "**Visualization**:\n",
    "\n",
    "![Fashion MNIST Noise Reduction](pics/fashion_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-extraction",
   "metadata": {
    "id": "feature-extraction"
   },
   "source": [
    "### 2.3 Feature Extraction\n",
    "\n",
    "**Dataset**: Labeled Faces in the Wild (LFW)\n",
    "\n",
    "**Description**:\n",
    "\n",
    "The LFW dataset consists of images of faces collected from the web. Each face is represented by high-dimensional pixel data.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "- Use PCA to extract principal components known as \"eigenfaces\".\n",
    "- Visualize the eigenfaces to understand the most significant features in the dataset.\n",
    "\n",
    "**Visualization**:\n",
    "\n",
    "![LFW Eigenfaces](pics/eigenfaces.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
